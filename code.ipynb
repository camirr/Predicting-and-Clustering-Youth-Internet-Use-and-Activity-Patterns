{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z80ljpoB6brE"
   },
   "source": [
    "# **Final Project COMPSCI 4411/9538**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mqMXRaiimfRa"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "f_BVFLaPGKnv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "import shap\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import urllib.parse\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, cohen_kappa_score, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from catboost import CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from kmodes.kmodes import KModes\n",
    "import os\n",
    "import urllib.parse\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CsOb-Ho37zim",
    "outputId": "d48711fc-046f-48bf-90b8-f77800b78170"
   },
   "outputs": [],
   "source": [
    "\n",
    "# URL of the file to download\n",
    "url = \"https://s.mx.sb/s/RZr8i3ewjkJr5RT/download/child-mind-institute-problematic-internet-use.zip\"\n",
    "\n",
    "# Parse the filename from the URL path\n",
    "parsed_url = urllib.parse.urlparse(url)\n",
    "filename = os.path.basename(parsed_url.path)\n",
    "\n",
    "# Check if the file already exists\n",
    "if not os.path.exists(filename):\n",
    "    print(f\"File {filename} does not exist. Downloading...\")\n",
    "\n",
    "    # Download the file using curl with progress bar\n",
    "    !curl -L --progress-bar -o \"{filename}\" \"{url}\"\n",
    "\n",
    "# Unzip the file if it exists\n",
    "if os.path.exists(filename):\n",
    "    print(f\"Unzipping {filename}...\")\n",
    "    !unzip -o \"{filename}\"\n",
    "else:\n",
    "    print(f\"File {filename} was not downloaded or is missing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcdFNzCx8puI"
   },
   "source": [
    "## EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gQE0d7jsmfRc"
   },
   "source": [
    "#### 1) Dataset preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AKMX8Mtt86To",
    "outputId": "293074a4-8bbf-4d62-a02a-0c0a289c4c65"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "train = train.drop(columns=\"id\")\n",
    "dict = pd.read_csv('data_dictionary.csv')\n",
    "print(train.shape)\n",
    "print(train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "qVhVAD1eDZAF",
    "outputId": "213ca2bf-31cb-41f2-a361-3ff65467efa7"
   },
   "outputs": [],
   "source": [
    "dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "WyQTptETER2z",
    "outputId": "d18c1f01-af89-4f27-bc56-32ec89bb2977"
   },
   "outputs": [],
   "source": [
    "dict[\n",
    "dict['Type'].str.contains('int') & ~dict['Type'].str.contains('categorical')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FJrxeVt6NTnN",
    "outputId": "55316ee1-59b9-41e1-fc18-0929c6679212"
   },
   "outputs": [],
   "source": [
    "print(dict[\n",
    "dict['Field'].str.contains('PreInt_EduHx-computerinternet_hoursday')\n",
    "][\"Value Labels\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxA1qXjcmfRc"
   },
   "source": [
    "#### 2) Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "Kk_yE8xumfRd",
    "outputId": "c33689c0-33a2-48d9-a61e-c8e616c20de7"
   },
   "outputs": [],
   "source": [
    "# Create a bar plot to visualize the total null values in each feature\n",
    "\n",
    "missing_count = train.isnull().sum().to_frame('null_count')\n",
    "missing_count['feature'] = missing_count.index\n",
    "missing_count['null_ratio'] = missing_count['null_count'] / len(train)\n",
    "missing_count = missing_count.sort_values('null_count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='feature', y='null_count', data=missing_count, palette='rainbow', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Total Null Values in train_df')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 630
    },
    "id": "VPSvlfgzmfRd",
    "outputId": "81f9415c-285c-48bb-b2cc-fe9adc41a988"
   },
   "outputs": [],
   "source": [
    "# Null values ​​in data with no missing values ​​in Sii\n",
    "target = train[train['sii'].notnull()]\n",
    "\n",
    "missing_count = target.isnull().sum().to_frame('null_count')\n",
    "missing_count['feature'] = missing_count.index\n",
    "missing_count['null_ratio'] = missing_count['null_count'] / len(target)\n",
    "missing_count = missing_count.sort_values('null_count', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='feature', y='null_count', data=missing_count, palette='rainbow', legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Train_df without null values ​​in sii')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdc3lESimfRe"
   },
   "source": [
    "#### 3) Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "3ngJRdZimfRf",
    "outputId": "4933b27c-b33d-4863-d979-d9ff93d4717b"
   },
   "outputs": [],
   "source": [
    "# Define a list of columns to be extracted from the dataset for analysis.\n",
    "columns_to_include = [\n",
    "    'PCIAT-PCIAT_Total', 'Basic_Demos-Age', 'Basic_Demos-Sex', 'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "    'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "    'Physical-Diastolic_BP', 'Physical-Systolic_BP', 'Physical-HeartRate',\n",
    "    'PreInt_EduHx-computerinternet_hoursday', 'SDS-SDS_Total_T', 'PAQ_A-PAQ_A_Total',\n",
    "    'PAQ_C-PAQ_C_Total', 'Fitness_Endurance-Max_Stage', 'Fitness_Endurance-Time_Mins',\n",
    "    'Fitness_Endurance-Time_Sec', 'FGC-FGC_CU', 'FGC-FGC_GSND', 'FGC-FGC_GSD',\n",
    "    'FGC-FGC_PU', 'FGC-FGC_SRL', 'FGC-FGC_SRR', 'FGC-FGC_TL', 'BIA-BIA_Activity_Level_num',\n",
    "    'BIA-BIA_BMC', 'BIA-BIA_BMI', 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW',\n",
    "    'BIA-BIA_FFM', 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "    'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM', 'BIA-BIA_TBW'\n",
    "]\n",
    "\n",
    "\n",
    "# Filter the dataset to include only rows where 'sii' is not null and select the specified columns.\n",
    "filtered_data = train[train['sii'].notnull()][columns_to_include]\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(filtered_data.corr(), annot=True, fmt=\".2f\", cmap='rainbow')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHXX74oUwbI6"
   },
   "source": [
    "#### 4) Features used in this analysis - Univariate Analysis & and Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "nZa083WjwbI6",
    "outputId": "b2294189-f523-4938-8563-d8b4fac9c533"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (FitnessGram Child, PCIAT)\n",
    "pciat_columns = [col for col in train.columns if 'PCIAT-' in col]\n",
    "\n",
    "# Combine all relevant columns\n",
    "df = train[pciat_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in df.columns if 'Season' in col]\n",
    "df = df.drop(columns=season_columns)\n",
    "\n",
    "\n",
    "# Numeric Data Visualization\n",
    "df.hist(bins=15, figsize=(15, 10), layout=(3, 7))\n",
    "plt.show()\n",
    "\n",
    "# Categorical Data Visualization\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(y=column, data=df)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "hsJe27liFUDe",
    "outputId": "015701bd-07d5-451e-bc75-ac28ff5cb24b"
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float64', 'int64']).plot(kind='box', subplots=True, layout=(3, 7), figsize=(12, 10), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "_XpLC1pjwbI7",
    "outputId": "0705f9ad-fe3d-4e25-9ecf-4e14873f8ec9"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (BIA)\n",
    "bia_columns = [col for col in train.columns if 'BIA-' in col]\n",
    "\n",
    "# Combine all relevant columns\n",
    "df = train[bia_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in df.columns if 'Season' in col]\n",
    "df = df.drop(columns=season_columns)\n",
    "\n",
    "\n",
    "# Numeric Data Visualization\n",
    "df.hist(bins=15, figsize=(15, 10), layout=(3, 7))\n",
    "plt.show()\n",
    "\n",
    "# Categorical Data Visualization\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(y=column, data=df)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "IfWfz-fdFBdh",
    "outputId": "eabac5ad-f211-4fe1-cd8a-f8aa07158140"
   },
   "outputs": [],
   "source": [
    "df.select_dtypes(include=['float64', 'int64']).plot(kind='box', subplots=True, layout=(3, 7), figsize=(12, 10), sharex=False, sharey=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 474
    },
    "id": "3WaUhMK16oYp",
    "outputId": "fea04d5c-9e70-48a6-c856-4f2997409722"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (FGC)\n",
    "fgc_columns = [col for col in train.columns if 'FGC' in col]\n",
    "\n",
    "# Combine all relevant columns\n",
    "df = train[fgc_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in df.columns if 'Season' in col]\n",
    "df = df.drop(columns=season_columns)\n",
    "\n",
    "\n",
    "# Numeric Data Visualization\n",
    "df.hist(bins=15, figsize=(15, 10), layout=(3, 7))\n",
    "plt.show()\n",
    "\n",
    "# Categorical Data Visualization\n",
    "for column in df.select_dtypes(include='object').columns:\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.countplot(y=column, data=df)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "hmwqlZHjmfRf",
    "outputId": "a484071c-66ce-451d-a398-887bd6112ca2"
   },
   "outputs": [],
   "source": [
    "# Box plots for all numeric variables\n",
    "df.select_dtypes(include=['float64', 'int64']).plot(kind='box', subplots=True, layout=(3, 7), figsize=(12, 10), sharex=False, sharey=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BZILia6mfRg"
   },
   "source": [
    "#### 5） Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "yxoWqAL3_2NN",
    "outputId": "9bc494f7-5bb7-439b-b14c-36e2b667035b"
   },
   "outputs": [],
   "source": [
    "# Distribution of SII Target Variable\n",
    "\n",
    "# Define the mapping for `sii` levels including \"Missing\" for NaNs\n",
    "sii_map = {\n",
    "    0: \"None\",\n",
    "    1: \"Mild\",\n",
    "    2: \"Moderate\",\n",
    "    3: \"Severe\",\n",
    "    \"missing\": \"Missing Data\"\n",
    "}\n",
    "\n",
    "# Replace NaN values with \"missing\" to count them as a separate category\n",
    "train['sii_filled'] = train['sii'].fillna(\"missing\")\n",
    "train['sii_label'] = train['sii_filled'].map(sii_map)\n",
    "\n",
    "# Count the occurrences for each `sii` level, including missing data\n",
    "sii_counts = train['sii_label'].value_counts()\n",
    "sii_percentages = (sii_counts / sii_counts.sum()) * 100\n",
    "\n",
    "# Create DataFrame for plotting with counts and percentages, placing \"Missing Data\" at the end\n",
    "sii_data = pd.DataFrame({\n",
    "    'SII Level': sii_counts.index,\n",
    "    'Count': sii_counts.values,\n",
    "    'Percentage': sii_percentages.values\n",
    "})\n",
    "\n",
    "# Reorder to ensure \"Missing Data\" is at the end\n",
    "sii_data['SII Level'] = pd.Categorical(\n",
    "    sii_data['SII Level'],\n",
    "    categories=[\"None\", \"Mild\", \"Moderate\", \"Severe\", \"Missing Data\"],\n",
    "    ordered=True\n",
    ")\n",
    "sii_data = sii_data.sort_values('SII Level')\n",
    "\n",
    "# Define color mapping based on sii levels\n",
    "colors = {\n",
    "    \"None\": \"#4B9CD3\",  # Blue\n",
    "    \"Mild\": \"#0074D9\",  # Darker Blue\n",
    "    \"Moderate\": \"#17BECF\",  # Teal\n",
    "    \"Severe\": \"#FF4136\",  # Red\n",
    "    \"Missing Data\": \"#A9A9A9\"  # Gray\n",
    "}\n",
    "\n",
    "# Plot the data using matplotlib\n",
    "bars = plt.bar(sii_data['SII Level'], sii_data['Count'], color=[colors[level] for level in sii_data['SII Level']])\n",
    "\n",
    "# Add count labels to each bar\n",
    "for bar, count in zip(bars, sii_data['Count']):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 5, str(count),\n",
    "             ha='center', va='bottom', color='white', fontsize=10, fontweight='bold')\n",
    "\n",
    "# Set the title and labels to match previous settings\n",
    "plt.title(\"Distribution of SII Target Variable\", fontsize=20, color=\"#004080\")\n",
    "plt.xlabel(\"SII Severity Level\", fontsize=14)\n",
    "plt.ylabel(\"Number of Participants\", fontsize=14)\n",
    "\n",
    "# Customize the plot appearance\n",
    "plt.gca().set_facecolor('white')\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtJCYXn1mfRh"
   },
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cI7NSuRllQ07"
   },
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VbzmypN55-4d",
    "outputId": "1a442b83-88ca-4264-86c4-a11b98853cf8"
   },
   "outputs": [],
   "source": [
    "df = train\n",
    "\n",
    "# Define the threshold for missing value percentage\n",
    "threshold = 0.5\n",
    "\n",
    "# Calculate the percentage of missing values in each column\n",
    "missing_percentage = df.isnull().sum() / len(df)\n",
    "\n",
    "# Drop columns with >50% missing values\n",
    "columns_to_remove = missing_percentage[missing_percentage > threshold].index.tolist()\n",
    "\n",
    "# Remove the identified columns from the DataFrame\n",
    "df_cleaned = df.drop(columns=columns_to_remove)\n",
    "\n",
    "# Check the structure of the cleaned DataFrame\n",
    "print(\"Structure of the cleaned DataFrame:\\n\", df_cleaned.info())\n",
    "\n",
    "# Check for missing values in the cleaned DataFrame\n",
    "missing_values_cleaned = df_cleaned.isnull().sum()\n",
    "print(\"\\nMissing values in the cleaned DataFrame:\\n\", missing_values_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69KMKuKawbI8"
   },
   "source": [
    "### Cluster 1 - PCIAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "07e7tknfRvLH",
    "outputId": "870fabc2-7a00-40ae-cc33-dd1e9a0fa8db"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns (FitnessGram Child, PCIAT)\n",
    "pciat_columns = [col for col in df_cleaned.columns if 'PCIAT-' in col]\n",
    "\n",
    "# Combine all relevant columns\n",
    "filtered_data = df_cleaned[pciat_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in filtered_data.columns if 'Season' in col]\n",
    "filtered_data = filtered_data.drop(columns=season_columns)\n",
    "filtered_data = filtered_data.drop(columns='PCIAT-PCIAT_Total')\n",
    "# Inspect missing values in the selected dataset\n",
    "print(\"Missing Values in Selected Data:\")\n",
    "print(filtered_data.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KA2wvE9mmfRi"
   },
   "source": [
    "##### 1) KNN & K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dPHRwkJmtqCE",
    "outputId": "463df793-488f-41de-8a2e-bbdde66181b0"
   },
   "outputs": [],
   "source": [
    "# Define the range of neighbors to test\n",
    "neighbor_values = [2,3,5,7,10]\n",
    "\n",
    "# Store results for evaluation\n",
    "imputed_datasets = {}\n",
    "\n",
    "for n in neighbor_values:\n",
    "    # Initialize the KNN Imputer with different numbers of neighbors\n",
    "    knn_imputer = KNNImputer(n_neighbors=n)\n",
    "\n",
    "    # Perform imputation\n",
    "    imputed_data = knn_imputer.fit_transform(filtered_data)\n",
    "\n",
    "    # Use the actual columns after imputation which are numbered\n",
    "    imputed_datasets[n] = pd.DataFrame(imputed_data)\n",
    "    print(f\"Imputation complete for n_neighbors={n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "jQr3pGwevSur",
    "outputId": "ba2e31bf-2c48-4bb7-84c3-50055e2a2626"
   },
   "outputs": [],
   "source": [
    "# Define the range of max_iter values to test\n",
    "max_iter_values = [5, 10, 20]\n",
    "\n",
    "# Store results for evaluation\n",
    "imputed_datasets_iterative = {}\n",
    "\n",
    "for max_iter in max_iter_values:\n",
    "    # Initialize the Iterative Imputer with different max_iter values\n",
    "    iterative_imputer = IterativeImputer(max_iter=max_iter, random_state=0)\n",
    "\n",
    "    # Perform imputation\n",
    "    imputed_data = iterative_imputer.fit_transform(filtered_data)\n",
    "\n",
    "    # Store the imputed dataset\n",
    "    imputed_datasets_iterative[max_iter] = pd.DataFrame(imputed_data, columns = filtered_data.columns)\n",
    "    print(f\"Iterative Imputation complete for max_iter={max_iter}\")\n",
    "\n",
    "\n",
    "# Replace with the index of your column of interest\n",
    "column_index = 0\n",
    "column_name = filtered_data.columns[column_index]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot distributions for KNN Imputation\n",
    "for n, imputed_df in imputed_datasets.items():\n",
    "    sns.kdeplot(imputed_df[column_index], label=f'KNN (n_neighbors={n})')\n",
    "\n",
    "# Plot distributions for Iterative Imputation\n",
    "for max_iter, imputed_df in imputed_datasets_iterative.items():\n",
    "    sns.kdeplot(imputed_df[column_name], label=f'Iterative (max_iter={max_iter})')\n",
    "\n",
    "# Plot the original distribution (if you have it)\n",
    "sns.kdeplot(filtered_data[column_name], label='Original Data')\n",
    "\n",
    "\n",
    "plt.xlabel(column_name)\n",
    "plt.ylabel('Density')\n",
    "plt.title(f'Distribution of {column_name} for Different Imputation Methods')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E_Tu2EJlC8K0",
    "outputId": "91c187ce-5c7b-422d-cf6b-f94cbc4f32cf"
   },
   "outputs": [],
   "source": [
    "# As they are all the same, we then choose to use KNN when n=5 to fill the missing values in relevant columns for PCIAT\n",
    "# and drop the column includes seasons\n",
    "\n",
    "# Initialize the KNN Imputer with n_neighbors=5\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Perform imputation\n",
    "filtered_data_imputed = knn_imputer.fit_transform(filtered_data)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "filtered_data_imputed = pd.DataFrame(filtered_data_imputed, columns=filtered_data.columns)\n",
    "\n",
    "print(filtered_data_imputed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F4S-guuqFKYp",
    "outputId": "afbfab70-bfd3-4c84-e126-7660b66ebc68"
   },
   "outputs": [],
   "source": [
    "# Perform imputation\n",
    "filtered_data_imputed = knn_imputer.fit_transform(filtered_data)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "filtered_data_imputed = pd.DataFrame(filtered_data_imputed, columns=filtered_data.columns)\n",
    "\n",
    "print(filtered_data_imputed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "UCPfNj6iEDi-",
    "outputId": "2c54a8ad-6011-4944-8dee-814995c7a21e"
   },
   "outputs": [],
   "source": [
    "# Do clustering for the relevant columns for FGC in filtered_data_imputed and visualized clustering and elbow\n",
    "# Scale the data\n",
    "scaled_data = filtered_data_imputed\n",
    "\n",
    "# Calculate the silhouette score for different numbers of clusters\n",
    "range_n_clusters = range(2, 11)\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_data)\n",
    "    silhouette_avg = silhouette_score(scaled_data, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "Os3JN4FumfRj",
    "outputId": "35afa9dc-2d11-4412-f547-a374db631e70"
   },
   "outputs": [],
   "source": [
    "# Elbow method\n",
    "inertia = []\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, random_state=0)\n",
    "    kmeans.fit(scaled_data)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method for Optimal k')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "Os2fT0YLmfRj",
    "outputId": "5840f477-d7c6-41f4-f5e6-88cd36e0b682"
   },
   "outputs": [],
   "source": [
    "# Based on the silhouette scores and elbow method, choose the optimal number of clusters\n",
    "optimal_k = 3\n",
    "\n",
    "# Perform KMeans clustering with the optimal k\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=0)\n",
    "filtered_data_imputed['cluster'] = kmeans.fit_predict(scaled_data)\n",
    "filtered_data_imputed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yrBUoqnqmfRj"
   },
   "source": [
    "##### 2) DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MYVmePbj3jAD",
    "outputId": "38645f42-a6a0-4435-abec-77404f812d55"
   },
   "outputs": [],
   "source": [
    "# Try different epsilon and min_samples values\n",
    "eps_values = [0.5, 1, 1.5, 2]\n",
    "min_samples_values = [5, 10, 15]\n",
    "\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(scaled_data)\n",
    "\n",
    "        # Check for only one cluster\n",
    "        if len(set(labels)) > 1:\n",
    "          silhouette = silhouette_score(scaled_data, labels)\n",
    "\n",
    "          print(f\"eps={eps}, min_samples={min_samples}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "          if silhouette > best_silhouette:\n",
    "              best_silhouette = silhouette\n",
    "              best_eps = eps\n",
    "              best_min_samples = min_samples\n",
    "\n",
    "# Apply DBSCAN with the best parameters found\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "filtered_data_imputed['cluster'] = dbscan.fit_predict(scaled_data)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(filtered_data_imputed.groupby('cluster').mean())\n",
    "\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (DBSCAN): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "-RcYpfIqmfRj",
    "outputId": "721ab1f7-f3a1-4652-af2f-9c8c83a2609a"
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=filtered_data_imputed.columns[0], y=filtered_data_imputed.columns[1], hue='cluster', data=filtered_data_imputed, palette='viridis')\n",
    "plt.title('DBSCAN Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wom5njfbmfRj"
   },
   "source": [
    "##### 3) GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9R6SZjWj6uMN",
    "outputId": "d14d5a5d-ebbc-4e69-989e-e9e1fda1f1de"
   },
   "outputs": [],
   "source": [
    "# Test different numbers of components\n",
    "n_components_range = range(2, 6)\n",
    "\n",
    "best_n_components = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "    labels = gmm.fit_predict(scaled_data)\n",
    "    silhouette = silhouette_score(scaled_data, labels)\n",
    "\n",
    "    print(f\"n_components={n_components}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "    if silhouette > best_silhouette:\n",
    "        best_silhouette = silhouette\n",
    "        best_n_components = n_components\n",
    "\n",
    "# Apply GMM with the best number of components\n",
    "gmm = GaussianMixture(n_components=best_n_components, random_state=0)\n",
    "filtered_data_imputed['cluster'] = gmm.fit_predict(scaled_data)\n",
    "\n",
    "# Analyze clusters\n",
    "print(filtered_data_imputed.groupby('cluster').mean())\n",
    "\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (GMM): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "HN06qSzlmfRo",
    "outputId": "40fcdb9e-a581-43ce-f1a7-e8f3ab1c449b"
   },
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=filtered_data_imputed.columns[0], y=filtered_data_imputed.columns[1], hue='cluster', data=filtered_data_imputed, palette='viridis')\n",
    "plt.title('GMM Clustering Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "feX8juG6-TiR"
   },
   "source": [
    "### Cluster 2 - BIA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsplICUlA5ld",
    "outputId": "507fc1f8-ae88-427d-b863-f55e75a52988"
   },
   "outputs": [],
   "source": [
    "# Select relevant columns starting with 'FGC' and ending with 'zone'\n",
    "bia_columns = [col for col in df_cleaned.columns if col.startswith('BIA')]\n",
    "filtered_data_bia = df_cleaned[bia_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in filtered_data_bia.columns if 'Season' in col]\n",
    "filtered_data_bia = filtered_data_bia.drop(columns=season_columns)\n",
    "\n",
    "# Inspect missing values in the selected dataset\n",
    "print(\"Missing Values in Selected Data:\")\n",
    "print(filtered_data_bia.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3K-br1ggRb5z",
    "outputId": "0872c9af-5848-4160-8bf9-5a0ed5282050"
   },
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on 'BIA-BIA_Frame_num'\n",
    "\n",
    "# One-hot encode the column\n",
    "bia_encoded = pd.get_dummies(filtered_data_bia['BIA-BIA_Frame_num'], prefix='BIA_Frame_num')\n",
    "\n",
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "filtered_data_bia = pd.concat([filtered_data_bia, bia_encoded], axis=1)\n",
    "\n",
    "# Drop the original 'BIA-BIA_Frame_num' column\n",
    "filtered_data_bia = filtered_data_bia.drop('BIA-BIA_Frame_num', axis=1)\n",
    "\n",
    "print(filtered_data_bia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IUsMCu7ZSrtt",
    "outputId": "a4491978-3c3b-407b-f433-c428c89e83dd"
   },
   "outputs": [],
   "source": [
    "# Identify continuous variables (numeric columns)\n",
    "continuous_cols = filtered_data_bia.select_dtypes(include=['number']).columns\n",
    "\n",
    "# Normalize using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "filtered_data_bia[continuous_cols] = scaler.fit_transform(filtered_data_bia[continuous_cols])\n",
    "\n",
    "print(filtered_data_bia.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vmy6eV5UD1Zt"
   },
   "source": [
    "#### 1) KNN & Kmodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "whTIWZV2A4nm",
    "outputId": "cd2047de-5959-4c19-f940-832d8d63565b"
   },
   "outputs": [],
   "source": [
    "# Perform imputation\n",
    "filtered_data_imputed_bia = knn_imputer.fit_transform(filtered_data_bia)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "filtered_data_imputed_bia = pd.DataFrame(filtered_data_imputed_bia, columns=filtered_data_bia.columns)\n",
    "\n",
    "print(filtered_data_imputed_bia.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "05mvbO2bEUgy",
    "outputId": "52558d60-5673-4268-cbda-bb2ff22b98ba"
   },
   "outputs": [],
   "source": [
    "scaled_data_bia = filtered_data_imputed_bia\n",
    "\n",
    "# Calculate the silhouette score for different numbers of clusters\n",
    "range_n_clusters = range(2, 11)\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmodes = KModes(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels = kmodes.fit_predict(scaled_data_bia)\n",
    "    silhouette_avg = silhouette_score(scaled_data_bia, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "FZCeFnw5D0vq",
    "outputId": "6e34111c-a336-4748-c9ba-14632c8c2423"
   },
   "outputs": [],
   "source": [
    "# Based on the silhouette scores and elbow method, choose the optimal number of clusters\n",
    "optimal_k = 4\n",
    "\n",
    "# Perform KMeans clustering with the optimal k\n",
    "kmodes = KModes(n_clusters=optimal_k, random_state=0)\n",
    "filtered_data_imputed_bia['cluster_bia'] = kmodes.fit_predict(scaled_data_bia)\n",
    "filtered_data_imputed_bia.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmuW_M80vSGm"
   },
   "source": [
    "#### 2) DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VazE0L_YvVkb",
    "outputId": "8d5926a5-ada0-49b8-8127-2dd03c8a40bd"
   },
   "outputs": [],
   "source": [
    "eps_values = [0.5, 1, 1.5, 2]\n",
    "min_samples_values = [5, 10, 15]\n",
    "\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(scaled_data_bia)\n",
    "\n",
    "        # Check for only one cluster\n",
    "        if len(set(labels)) > 1:\n",
    "          silhouette = silhouette_score(scaled_data_bia, labels)\n",
    "\n",
    "          print(f\"eps={eps}, min_samples={min_samples}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "          if silhouette > best_silhouette:\n",
    "              best_silhouette = silhouette\n",
    "              best_eps = eps\n",
    "              best_min_samples = min_samples\n",
    "\n",
    "# Apply DBSCAN with the best parameters found\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "filtered_data_imputed_bia['cluster_bia'] = dbscan.fit_predict(scaled_data_bia)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(filtered_data_imputed_bia.groupby('cluster_bia').mean())\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (DBSCAN): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bwg8dPb8wM54"
   },
   "source": [
    "#### 3) GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXsP6vr8v1Cq",
    "outputId": "68036993-6a62-4a84-93b2-4103b619dd1d"
   },
   "outputs": [],
   "source": [
    "# Test different numbers of components\n",
    "n_components_range = range(2, 6)\n",
    "\n",
    "best_n_components = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "    labels = gmm.fit_predict(scaled_data_bia)\n",
    "    silhouette = silhouette_score(scaled_data_bia, labels)\n",
    "\n",
    "    print(f\"n_components={n_components}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "    if silhouette > best_silhouette:\n",
    "        best_silhouette = silhouette\n",
    "        best_n_components = n_components\n",
    "\n",
    "# Apply GMM with the best number of components\n",
    "gmm = GaussianMixture(n_components=best_n_components, random_state=0)\n",
    "filtered_data_imputed_bia['cluster_bia'] = gmm.fit_predict(scaled_data_bia)\n",
    "\n",
    "# Analyze clusters\n",
    "print(filtered_data_imputed_bia.groupby('cluster_bia').mean())\n",
    "\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (GMM): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K2m1Rg0h4wjX"
   },
   "source": [
    "### Cluster 3 - FGC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DG_ZTOME40Mg",
    "outputId": "01a9a338-a2b7-487b-d6c8-955e9a060ffa"
   },
   "outputs": [],
   "source": [
    "fgc_columns = [col for col in df_cleaned.columns if col.startswith('FGC') and col.endswith('Zone')]\n",
    "filtered_data_fgc = df_cleaned[fgc_columns]\n",
    "\n",
    "#drop season columns\n",
    "season_columns = [col for col in filtered_data_fgc.columns if 'Season' in col]\n",
    "filtered_data_fgc = filtered_data_fgc.drop(columns=season_columns)\n",
    "\n",
    "# Inspect missing values in the selected dataset\n",
    "print(\"Missing Values in Selected Data:\")\n",
    "print(filtered_data_fgc.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EZP7Y63A6FA8",
    "outputId": "8d175709-0b25-473e-cc04-1e354f2ce464"
   },
   "outputs": [],
   "source": [
    "filtered_data_imputed_fgc = knn_imputer.fit_transform(filtered_data_fgc)\n",
    "\n",
    "# Convert the imputed data back to a DataFrame\n",
    "filtered_data_imputed_fgc = pd.DataFrame(filtered_data_imputed_fgc, columns=filtered_data_fgc.columns)\n",
    "\n",
    "print(filtered_data_imputed_fgc.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6Wy-l9DwbJM"
   },
   "source": [
    "#### 1) KNN & KModes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "id": "L-v3-p4s5UYq",
    "outputId": "e7435131-9fc4-490e-be04-3f075a21368d"
   },
   "outputs": [],
   "source": [
    "scaled_data_fgc = filtered_data_imputed_fgc\n",
    "\n",
    "# Calculate the silhouette score for different numbers of clusters\n",
    "range_n_clusters = range(2, 11)\n",
    "silhouette_scores = []\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    kmodes = KModes(n_clusters=n_clusters, random_state=0)\n",
    "    cluster_labels = kmodes.fit_predict(scaled_data_fgc)\n",
    "    silhouette_avg = silhouette_score(scaled_data_fgc, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {n_clusters}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.plot(range_n_clusters, silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Analysis for Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XYWlnm7D9HbR",
    "outputId": "8cb92974-5070-4459-d161-1b27b397359b"
   },
   "outputs": [],
   "source": [
    "# Elbow method for KModes\n",
    "cost = []\n",
    "K = range(1,11)\n",
    "for num_clusters in list(K):\n",
    "    kmode = KModes(n_clusters=num_clusters, init = \"Cao\", n_init = 1, verbose=1)\n",
    "    kmode.fit_predict(scaled_data_fgc)\n",
    "    cost.append(kmode.cost_)\n",
    "\n",
    "plt.plot(K, cost, 'bx-')\n",
    "plt.xlabel('No. of clusters')\n",
    "plt.ylabel('Cost')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YXOIOBPx6eYL",
    "outputId": "8d24f103-d30a-4dd2-d9fa-9b23812f80ab"
   },
   "outputs": [],
   "source": [
    "optimal_k = 5\n",
    "\n",
    "# Perform KMeans clustering with the optimal k\n",
    "kmodes = KModes(n_clusters=optimal_k, random_state=0)\n",
    "filtered_data_imputed_fgc['cluster_fgc'] = kmodes.fit_predict(scaled_data_fgc)\n",
    "filtered_data_imputed_fgc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ePmaSCli9awQ"
   },
   "source": [
    "#### 2) DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-SMGfoT9TXo",
    "outputId": "43ad39d0-6cfc-4e53-fd4c-d0cc9f2a4ccc"
   },
   "outputs": [],
   "source": [
    "eps_values = [0.5, 1, 1.5, 2]\n",
    "min_samples_values = [5, 10, 15]\n",
    "\n",
    "best_eps = None\n",
    "best_min_samples = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for eps in eps_values:\n",
    "    for min_samples in min_samples_values:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(scaled_data_fgc)\n",
    "\n",
    "        # Check for only one cluster\n",
    "        if len(set(labels)) > 1:\n",
    "          silhouette = silhouette_score(scaled_data_fgc, labels)\n",
    "\n",
    "          print(f\"eps={eps}, min_samples={min_samples}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "          if silhouette > best_silhouette:\n",
    "              best_silhouette = silhouette\n",
    "              best_eps = eps\n",
    "              best_min_samples = min_samples\n",
    "\n",
    "# Apply DBSCAN with the best parameters found\n",
    "dbscan = DBSCAN(eps=best_eps, min_samples=best_min_samples)\n",
    "filtered_data_imputed_fgc['cluster_fgc'] = dbscan.fit_predict(scaled_data_fgc)\n",
    "\n",
    "# Analyze the clusters\n",
    "print(filtered_data_imputed_fgc.groupby('cluster_fgc').mean())\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (DBSCAN): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEzMrlRE-fyf"
   },
   "source": [
    "#### 3）GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ez67Etg6-fDI",
    "outputId": "6695491d-4920-43b1-c7a3-6acff1a2bdba"
   },
   "outputs": [],
   "source": [
    "# Test different numbers of components\n",
    "n_components_range = range(2, 6)\n",
    "\n",
    "best_n_components = None\n",
    "best_silhouette = -1\n",
    "\n",
    "for n_components in n_components_range:\n",
    "    gmm = GaussianMixture(n_components=n_components, random_state=0)\n",
    "    labels = gmm.fit_predict(scaled_data_fgc)\n",
    "    silhouette = silhouette_score(scaled_data_fgc, labels)\n",
    "\n",
    "    print(f\"n_components={n_components}, Silhouette Score: {silhouette}\")\n",
    "\n",
    "    if silhouette > best_silhouette:\n",
    "        best_silhouette = silhouette\n",
    "        best_n_components = n_components\n",
    "\n",
    "# Apply GMM with the best number of components\n",
    "gmm = GaussianMixture(n_components=best_n_components, random_state=0)\n",
    "filtered_data_imputed_fgc['cluster_fgc'] = gmm.fit_predict(scaled_data_fgc)\n",
    "\n",
    "# Analyze clusters\n",
    "print(filtered_data_imputed_fgc.groupby('cluster_fgc').mean())\n",
    "print(filtered_data_imputed_fgc)\n",
    "# Calculate Silhouette Score for the best model\n",
    "print(f\"Best Silhouette Score (GMM): {best_silhouette}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlDfqX3EZnQb"
   },
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jiZwBSrpmfRo"
   },
   "source": [
    "#### 1) Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQcOZsp3JPa3",
    "outputId": "940ddf08-faf1-478d-babf-b32e30054d63"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in columns starting with 'Physical' with the median\n",
    "physical_columns = [col for col in df_cleaned.columns if col.startswith('Physical')]\n",
    "filtered_data_su = df_cleaned[physical_columns]\n",
    "\n",
    "# Drop the column that has Season so that all missing value will be filled with median and do train-spilt\n",
    "season_columns = [col for col in filtered_data_su.columns if 'Season' in col]\n",
    "filtered_data_su = filtered_data_su.drop(columns=season_columns)\n",
    "print(\"Missing Values in Selected Data:\")\n",
    "print(filtered_data_su.isnull().sum().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z2uzqFD9cuwP",
    "outputId": "e0febcb0-ed89-49ef-dc2f-d0349006b94c"
   },
   "outputs": [],
   "source": [
    "# Fill missing values with the median for each column\n",
    "for col in filtered_data_su.columns:\n",
    "    median_value = filtered_data_su[col].median()\n",
    "    filtered_data_su[col].fillna(median_value, inplace=True)\n",
    "\n",
    "print(\"Missing Values after Median Imputation:\")\n",
    "print(filtered_data_su.isnull().sum().sort_values(ascending=False))\n",
    "\n",
    "# Use median to filled the missing value for sii\n",
    "df_cleaned['sii'].fillna(df_cleaned['sii'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9KTrWr5mfRp",
    "outputId": "badada2c-6134-46ef-9ab7-bdab7bd021e9"
   },
   "outputs": [],
   "source": [
    "# Use the cluster labels as new features\n",
    "filtered_data_su['cluster'] = kmeans.fit_predict(scaled_data)\n",
    "filtered_data_su['cluster_bia'] = dbscan.fit_predict(scaled_data_bia)\n",
    "filtered_data_su['cluster_fgc'] = gmm.fit_predict(scaled_data_fgc)\n",
    "print(filtered_data_su.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "LOOsDckPgvCL"
   },
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "X = filtered_data_su\n",
    "y = df_cleaned['sii']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i-MSJvG9mfRq",
    "outputId": "ae76b312-67bc-4225-8b89-62876a20eda1"
   },
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Apply SMOTE to the training data\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Check the class distribution after SMOTE\n",
    "print(np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NsDQSZF-mfRq"
   },
   "source": [
    "#### 2) Baseline - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2WVvUTOmfRq",
    "outputId": "169136c1-5dd0-42d5-ffac-ccce0a47b90e"
   },
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression model with multi_class set to 'multinomial'\n",
    "baseline_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='multinomial')\n",
    "baseline_pipeline = make_pipeline(StandardScaler(), baseline_model)\n",
    "baseline_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_base = baseline_pipeline.predict(X_test)\n",
    "y_score_base = baseline_pipeline.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "xzc4slVxmfRq",
    "outputId": "84971710-05a4-4436-a4f4-e17f578b6069"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_base)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "GuUFCr35mfRr",
    "outputId": "dee27625-f8ae-4805-fc80-fa8b926ab5bc"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score_base.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score_base[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFEvanI8mfRr",
    "outputId": "7853dc8c-4b7d-43a0-ae9a-cd9a3a3acf8a"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_base = accuracy_score(y_test, y_pred_base)\n",
    "precision_base = precision_score(y_test, y_pred_base, average='weighted', zero_division=0)\n",
    "recall_base = recall_score(y_test, y_pred_base, average='weighted')\n",
    "f1_base = f1_score(y_test, y_pred_base, average='weighted')\n",
    "kappa_base = cohen_kappa_score(y_test, y_pred_base)\n",
    "roc_auc_base = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2, 3]), y_score_base, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_base:}\")\n",
    "print(f\"Precision: {precision_base:}\")\n",
    "print(f\"Recall: {recall_base:}\")\n",
    "print(f\"F1 Score: {f1_base:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_base:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_base:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jWgYw0l6mfRr"
   },
   "source": [
    "#### 3) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Y6pSqQXGygm",
    "outputId": "fb50b7d2-781c-4795-9f02-5aa719ab266c"
   },
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 500],  \n",
    "    'max_depth': [None, 10, 20, 30],     \n",
    "    'min_samples_split': [2, 5, 10],    \n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output the best parameters and accuracy\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best Accuracy: {grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "zaRGp7aWiU4d"
   },
   "outputs": [],
   "source": [
    "# Create a RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(max_depth=20, min_samples_split=2, n_estimators=500, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "y_score_rf = rf_classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "dJWaTNNKmfRr",
    "outputId": "0c27331b-2b50-4cf8-ea55-12f9b3c01148"
   },
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance from Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "I43iQ5FQmfRs",
    "outputId": "d977e57f-e720-4ddd-b1cc-b370ade51cff"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "VMZSdr68mfRs",
    "outputId": "b45e4ae7-8fa3-40c4-ed99-65fc427956e4"
   },
   "outputs": [],
   "source": [
    "# SHAP values for model interpretability\n",
    "explainer = shap.TreeExplainer(rf_classifier)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:100,:])\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100,:], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "ZKja4UtXmfRs",
    "outputId": "90f86d78-df82-4848-c7a8-934ee49e700c"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score_rf.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score_rf[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Jb13J92g-T7",
    "outputId": "7fd8c619-e3b7-40e6-b48f-645b51738fa9"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, average='weighted', zero_division=0)\n",
    "recall_rf = recall_score(y_test, y_pred_rf, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, average='weighted')\n",
    "kappa_rf = cohen_kappa_score(y_test, y_pred_rf)\n",
    "roc_auc_rf = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2, 3]), y_score_rf, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_rf:}\")\n",
    "print(f\"Precision: {precision_rf:}\")\n",
    "print(f\"Recall: {recall_rf:}\")\n",
    "print(f\"F1 Score: {f1_rf:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_rf:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_rf:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bNvxuu-FmfRs"
   },
   "source": [
    "#### 3) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "PgOJJWsAhwIY"
   },
   "outputs": [],
   "source": [
    "# Initialize and train the XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_score_xgb = xgb_model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "jQjbMp5VmfRs",
    "outputId": "d61849af-ce8e-4dcd-ee63-129e97893afa"
   },
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "feature_importances = xgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance from XGboost')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "JXKPKALnmfRs",
    "outputId": "674b256a-b5ae-4fee-c1cb-8c949f1b78d9"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_xgb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "0IIaCMeymfRs",
    "outputId": "9ce50957-85d3-46ee-b7cf-4756e007396f"
   },
   "outputs": [],
   "source": [
    "# SHAP values for model interpretability\n",
    "explainer = shap.TreeExplainer(xgb_model)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:100,:])\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100,:], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "ffYpBrb8mfRs",
    "outputId": "66f1a111-fff7-4cf9-b4a6-d3fd2fa1b993"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score_xgb.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score_xgb[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I-SfX-eWmfRs",
    "outputId": "b22282c9-79b3-4999-d285-40b8964f4c5e"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted', zero_division=0)\n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "kappa_xgb = cohen_kappa_score(y_test, y_pred_xgb)\n",
    "roc_auc_xgb = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2, 3]), y_score_xgb, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_xgb:}\")\n",
    "print(f\"Precision: {precision_xgb:}\")\n",
    "print(f\"Recall: {recall_xgb:}\")\n",
    "print(f\"F1 Score: {f1_xgb:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_xgb:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_xgb:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DuS5BQR-mfRt"
   },
   "source": [
    "#### 4) Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3oFvY_1ImfRt",
    "outputId": "d23a44be-466c-4a94-cfdf-39038e78a40c"
   },
   "outputs": [],
   "source": [
    "# Define the model structure\n",
    "model_nn = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model_nn.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "y_train_encoded = to_categorical(y_train, num_classes=4)\n",
    "y_test_encoded = to_categorical(y_test, num_classes=4)\n",
    "\n",
    "# Retrain the model with the one-hot encoded targets\n",
    "\n",
    "model_nn.fit(X_train, y_train_encoded, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set with one-hot encoded targets\n",
    "loss, accuracy = model_nn.evaluate(X_test, y_test_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kWf4_WOYmfRt",
    "outputId": "90b721cf-e13a-41aa-9aaf-b15434358522"
   },
   "outputs": [],
   "source": [
    "# Get probability distributions for each class\n",
    "y_prob_nn = model_nn.predict(X_test)\n",
    "\n",
    "y_pred = np.argmax(y_prob_nn, axis=1)\n",
    "\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "\n",
    "# Convert y_test to binary format for ROC AUC\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy_nn = accuracy_score(y_test, y_pred)\n",
    "precision_nn = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall_nn = recall_score(y_test, y_pred, average='weighted')\n",
    "f1_nn = f1_score(y_test, y_pred, average='weighted')\n",
    "kappa_nn = cohen_kappa_score(y_test, y_pred)\n",
    "roc_auc_nn = roc_auc_score(y_test_bin, y_prob_nn, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_nn:}\")\n",
    "print(f\"Precision: {precision_nn:}\")\n",
    "print(f\"Recall: {recall_nn:}\")\n",
    "print(f\"F1 Score: {f1_nn:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_nn:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_nn:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wLjb1BAsmfRt"
   },
   "source": [
    "#### 5) CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9L-qtbzNmfRt",
    "outputId": "57af1b34-3d96-467a-9a4a-89dd4b23da39"
   },
   "outputs": [],
   "source": [
    "# Initialize the CatBoost classifier\n",
    "catboost_model = CatBoostClassifier(iterations=500,\n",
    "                                     learning_rate=0.1,\n",
    "                                     depth=6,\n",
    "                                     random_seed=42,\n",
    "                                     verbose=100)\n",
    "\n",
    "# Train the model\n",
    "catboost_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_Cat = catboost_model.predict(X_test)\n",
    "y_prob_Cat = catboost_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "ykymAWLFmfRt",
    "outputId": "0a43d519-e548-482e-eeba-70dadf1717de"
   },
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "feature_importances = catboost_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance from CatBoost')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "oZl5XOmGmfRt",
    "outputId": "d8cda495-bec8-46f2-8374-8745a7a9c131"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_Cat)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "V1btiYQimfRt",
    "outputId": "dfe1a80e-748e-4034-8272-24e61dd87601"
   },
   "outputs": [],
   "source": [
    "# SHAP values for model interpretability\n",
    "explainer = shap.TreeExplainer(catboost_model)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:100,:])\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100,:], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "hc6btRvPmfRt",
    "outputId": "7900371f-7295-42d2-8a9e-d15afe3fffc5"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_prob_Cat.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob_Cat[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OZC7cw4RmfRt",
    "outputId": "db8089ae-3e5f-46a8-996d-cbfc6f79e160"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics for CatBoost model\n",
    "accuracy_Cat = accuracy_score(y_test, y_pred_Cat)\n",
    "precision_Cat = precision_score(y_test, y_pred_Cat, average='weighted', zero_division=0)\n",
    "recall_Cat = recall_score(y_test, y_pred_Cat, average='weighted')\n",
    "f1_Cat = f1_score(y_test, y_pred_Cat, average='weighted')\n",
    "kappa_Cat = cohen_kappa_score(y_test, y_pred_Cat)\n",
    "roc_auc_Cat = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2, 3]), y_prob_Cat, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_Cat:}\")\n",
    "print(f\"Precision: {precision_Cat:}\")\n",
    "print(f\"Recall: {recall_Cat:}\")\n",
    "print(f\"F1 Score: {f1_Cat:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_Cat:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_Cat:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ck_VE1ojmfRt"
   },
   "source": [
    "#### 6) LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-hWmp-zmfRt",
    "outputId": "87d97c21-9360-4646-fd7a-dac11482038e"
   },
   "outputs": [],
   "source": [
    "# Initialize the LightGBM classifier\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_LGB = lgb_model.predict(X_test)\n",
    "y_prob_LGB = lgb_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "xzeMEsfZmfRt",
    "outputId": "f87a2427-025a-4ee5-e89e-6a2905968020"
   },
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "feature_importances = lgb_model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for better visualization\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "plt.title('Feature Importance from LightGBM')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "v5N7YMgEmfRu",
    "outputId": "bd9d1b81-c98d-42f5-8e76-1e0b33fb79df"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_LGB)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "7gXAQSuVmfRu",
    "outputId": "7519a7ea-db74-400a-bf76-ba57f1da4723"
   },
   "outputs": [],
   "source": [
    "# SHAP values for model interpretability\n",
    "explainer = shap.TreeExplainer(lgb_model)\n",
    "shap_values = explainer.shap_values(X_test.iloc[:100,:])\n",
    "shap.summary_plot(shap_values, X_test.iloc[:100,:], plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "Fg95Ad8ImfRu",
    "outputId": "034395d5-535f-47a0-b05d-2c3aaeffe7cd"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_prob_LGB.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob_LGB[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WdC2Y_a1mfRv",
    "outputId": "c6662806-9c1d-4dd3-db64-4e0eed694c9c"
   },
   "outputs": [],
   "source": [
    "# Binarize labels for ROC-AUC\n",
    "y_test_bin = label_binarize(y_test, classes=np.unique(y_test))\n",
    "\n",
    "# Metrics calculation\n",
    "accuracy_LGB = accuracy_score(y_test, y_pred_LGB)\n",
    "precision_LGB = precision_score(y_test, y_pred_LGB, average='weighted')\n",
    "recall_LGB = recall_score(y_test, y_pred_LGB, average='weighted')\n",
    "f1_LGB = f1_score(y_test, y_pred_LGB, average='weighted')\n",
    "kappa_LGB = cohen_kappa_score(y_test, y_pred_LGB)\n",
    "roc_auc_LGB = roc_auc_score(y_test_bin, y_prob_LGB, multi_class='ovr')\n",
    "\n",
    "# Output metrics\n",
    "print(f\"Precision: {precision_LGB:}\")\n",
    "print(f\"Recall: {recall_LGB:}\")\n",
    "print(f\"F1 Score: {f1_LGB:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_LGB:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_LGB:}\")\n",
    "print(f\"LightGBM Accuracy: {accuracy_LGB:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oIBf8HB8mfRv"
   },
   "source": [
    "#### 7) Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "ZeQJlUBimfRv",
    "outputId": "8af8c6a1-8482-45f8-efcc-d9c8a4d15d06"
   },
   "outputs": [],
   "source": [
    "svm_classifier = SVC(kernel='linear', probability=True, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "pca = PCA(n_components=7)\n",
    "X_train_pca = pca.fit_transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "svm_classifier.fit(X_train_pca, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-KdNLQkmfRw",
    "outputId": "eb243d43-acee-47b5-9b9f-80b3a4906d8f"
   },
   "outputs": [],
   "source": [
    "# Create an SVM classifier with one-vs-rest strategy\n",
    "\n",
    "svm_classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_svm = svm_classifier.predict(X_test_scaled)\n",
    "\n",
    "y_score_svm = svm_classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "mTWJwtzlmfRw",
    "outputId": "f1cc2591-522d-49b8-863f-80a894e69f81"
   },
   "outputs": [],
   "source": [
    "# Feature Importance (only for linear kernel)\n",
    "if svm_classifier.kernel == 'linear':\n",
    "    feature_importances = np.abs(svm_classifier.coef_).sum(axis=0)\n",
    "    feature_names = X.columns\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Importance', y='Feature', data=feature_importance_df)\n",
    "    plt.title('Feature Importance from SVM')\n",
    "    plt.xlabel('Importance')\n",
    "    plt.ylabel('Feature')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "ucAQ2j_xmfRw",
    "outputId": "bc6be0a7-1a8c-4b49-9b71-cd68f9de3e33"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_svm)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix for SVM')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "6G79A06UmfRw",
    "outputId": "92a8e294-82b8-4d68-c4f3-d27b00e430f9"
   },
   "outputs": [],
   "source": [
    "# ROC\n",
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score_svm.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_score_svm[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5LYYXZnmfRx",
    "outputId": "f37b85ab-170a-4854-e543-c83411c10188"
   },
   "outputs": [],
   "source": [
    "# Metrics\n",
    "\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm, average='weighted', zero_division=0)\n",
    "recall_svm = recall_score(y_test, y_pred_svm, average='weighted')\n",
    "f1_svm = f1_score(y_test, y_pred_svm, average='weighted')\n",
    "kappa_svm = cohen_kappa_score(y_test, y_pred_svm)\n",
    "roc_auc_svm = roc_auc_score(y_test_bin, y_score_svm, multi_class='ovr')\n",
    "\n",
    "print(f\"Accuracy: {accuracy_svm}\")\n",
    "print(f\"Precision: {precision_svm}\")\n",
    "print(f\"Recall: {recall_svm}\")\n",
    "print(f\"F1 Score: {f1_svm}\")\n",
    "print(f\"Cohen's Kappa: {kappa_svm:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_svm:}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MdADU5GSmfRx"
   },
   "source": [
    "#### 8) Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "mi3029AkmfRx"
   },
   "outputs": [],
   "source": [
    "# Define the base learners\n",
    "base_learners = [\n",
    "    ('xgb', xgb_model),\n",
    "    ('cat', catboost_model),\n",
    "    ('light', lgb_model)\n",
    "]\n",
    "\n",
    "# Define the meta-learner\n",
    "meta_learner = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g4QQfBpDmfRx",
    "outputId": "41c36664-50ed-4606-bb5d-e865df14f14c"
   },
   "outputs": [],
   "source": [
    "# Initialize the Stacking Classifier with a classification meta-learner\n",
    "stacked_model = StackingClassifier(estimators=base_learners, final_estimator=meta_learner, cv=5)\n",
    "\n",
    "# Assume X_train, y_train are your training data\n",
    "stacked_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oq-D_56pmfRy",
    "outputId": "34f7c255-1030-405a-fc63-2b25edeaff4c"
   },
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_ens = stacked_model.predict(X_test)\n",
    "y_score_ens = stacked_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "Uax5rAmdmfRy",
    "outputId": "a8cb94ec-5b59-4d54-df86-f156f030ec0a"
   },
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_ens)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "gOqqgpklmfRy",
    "outputId": "950dd965-04dc-4de3-dfc4-1096798993b5"
   },
   "outputs": [],
   "source": [
    "# Binarize y_test if multiclass\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3])\n",
    "fpr, tpr, _ = roc_curve(y_test_bin.ravel(), y_score_ens.ravel())\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 4\n",
    "\n",
    "# Store FPR, TPR, and AUC for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i],  y_score_ens[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = ['blue', 'red', 'green', 'purple']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "\n",
    "# Plot the diagonal (random classifier)\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Multiclass ROC Curves')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M17RwIF8mfRy",
    "outputId": "4072fb4f-c057-48ac-b280-3c0a3f27c312"
   },
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "accuracy_ens = accuracy_score(y_test, y_pred_ens)\n",
    "precision_ens = precision_score(y_test, y_pred_ens, average='weighted', zero_division=0)\n",
    "recall_ens = recall_score(y_test, y_pred_ens, average='weighted')\n",
    "f1_ens = f1_score(y_test, y_pred_ens, average='weighted')\n",
    "kappa_ens = cohen_kappa_score(y_test, y_pred_ens)\n",
    "roc_auc_ens = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2, 3]), y_score_ens, average='macro', multi_class='ovr')\n",
    "\n",
    "# Output the metrics\n",
    "print(f\"Accuracy: {accuracy_ens:}\")\n",
    "print(f\"Precision: {precision_ens:}\")\n",
    "print(f\"Recall: {recall_ens:}\")\n",
    "print(f\"F1 Score: {f1_ens:}\")\n",
    "print(f\"Cohen's Kappa: {kappa_ens:}\")\n",
    "print(f\"ROC-AUC: {roc_auc_ens:}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9) Models Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w-uIGD28mfRz",
    "outputId": "71c593ba-c398-49e2-f131-3bc9e5150092"
   },
   "outputs": [],
   "source": [
    "# Creating DataFrame\n",
    "metrics_df_1 = pd.DataFrame({\n",
    "    \"Model\": [\"Baseline\", \"Random Forest\", \"XGBoost\", \"Neural Network\",\"CatBoost\", \"LightGBM\", \"SVM\", \"Ensemble\"],\n",
    "    \"Accuracy\": [accuracy_base, accuracy_rf, accuracy_xgb, accuracy_nn, accuracy_Cat, accuracy_LGB, accuracy_svm, accuracy_ens],\n",
    "    \"Precision\": [precision_base, precision_rf, precision_xgb, precision_nn, precision_Cat, precision_LGB, precision_svm, precision_ens],\n",
    "    \"Recall\": [recall_base, recall_rf, recall_xgb, recall_nn, recall_Cat, recall_LGB, recall_svm, recall_ens],\n",
    "    \"F1 Score\": [f1_base,f1_rf, f1_xgb, f1_nn, f1_Cat, f1_LGB, f1_svm, f1_ens],\n",
    "})\n",
    "\n",
    "metrics_df_2 = pd.DataFrame({\n",
    "    \"Model\": [\"Baseline\",\"Random Forest\", \"XGBoost\", \"Neural Network\",\"CatBoost\",\"LightGBM\", \"SVM\",\"Ensemble\"],\n",
    "    \"Cohen's Kappa\": [kappa_base,kappa_rf, kappa_xgb, kappa_nn, kappa_Cat, kappa_LGB, kappa_svm, kappa_ens],\n",
    "    \"ROC-AUC\": [roc_auc_base, roc_auc_rf, roc_auc_xgb, roc_auc_nn, roc_auc_Cat, roc_auc_LGB, roc_auc_svm, roc_auc_ens]\n",
    "})\n",
    "# Display the DataFrame\n",
    "print(metrics_df_1)\n",
    "print(\"\")\n",
    "print(metrics_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Top 3 models based on their performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BS_kGQlbwbJe"
   },
   "outputs": [],
   "source": [
    "# Merging both DataFrames\n",
    "metrics_combined = pd.merge(metrics_df_1, metrics_df_2, on=\"Model\")\n",
    "\n",
    "# Adding a rank column based on Accuracy, Precision, Recall, F1 Score, Cohen's Kappa, and ROC-AUC\n",
    "metrics_combined[\"Average Rank\"] = metrics_combined[\n",
    "    [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"Cohen's Kappa\", \"ROC-AUC\"]\n",
    "].mean(axis=1)\n",
    "\n",
    "# Sorting by Average Rank to find the best model\n",
    "metrics_combined = metrics_combined.sort_values(by=\"Average Rank\", ascending=False)\n",
    "\n",
    "# Display only the top 3 models\n",
    "top_3_models = metrics_combined.head(3)\n",
    "print(top_3_models)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "7BZILia6mfRg",
    "cI7NSuRllQ07",
    "yrBUoqnqmfRj",
    "Wom5njfbmfRj"
   ],
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
